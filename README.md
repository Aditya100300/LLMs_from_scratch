# üß† Building LLM Applications From Scratch ‚Äì My Learning Notebook

This is my personal implementation and learning journey based on the GitHub repository  
[**building-llm-applications-from-scratch**](https://github.com/hamzafarooq/building-llm-applications-from-scratch) by **Hamza Farooq**.

As a Master's student in Applied Data Science deeply interested in **LLMs, retrieval systems, and AI agents**, this repo helps me understand and **build real-world LLM applications** from scratch ‚Äî with minimal abstractions and maximum clarity.

---

## üéØ My Goals

- Learn to build end-to-end LLM-based applications with OpenAI and open-source models.
- Understand the internal flow of Retrieval-Augmented Generation (RAG), embeddings, and vector stores.
- Explore tools like **LangChain**, **LlamaIndex**, **ChromaDB**, **FAISS**, and others from scratch.
- Build an intuitive foundation on prompt engineering, memory, agents, and tool use.
- Document all findings, struggles, and implementations for long-term understanding.

---

## üìò What This Repo Covers (With My Implementation)

| Notebook / App               | What I‚Äôm Learning                                  |
|-----------------------------|-----------------------------------------------------|
| `1-prompt-engineering.ipynb`| Principles of prompt design, few-shot learning     |
| `2-rag-from-scratch.ipynb`  | Build RAG pipeline with ChromaDB, embeddings       |
| `3-multi-pdf-rag.ipynb`     | Chunking multiple docs, building a retrieval engine|
| `4-langchain-rag.ipynb`     | LangChain RAG workflows, chains, vector stores     |
| `5-llamaindex-rag.ipynb`    | Using LlamaIndex for structured data retrieval     |
| `6-openai-tools.ipynb`      | Function calling with OpenAI, API integration      |
| `7-memory.ipynb`            | Chat memory, context windows, conversation state   |
| `8-agents.ipynb`            | LangChain Agents, tool-use, and dynamic control    |

I am modifying the notebooks as I go, adding:
- ‚úÖ My own experiments
- ‚úÖ Comments and explanations
- ‚úÖ Notes on limitations, assumptions, and extensions

---

## üì¶ Tools & Stack

- **Python**
- **OpenAI API**
- **LangChain** & **LlamaIndex**
- **ChromaDB**, **FAISS**, **Pinecone**
- **Streamlit** for UI (in later notebooks)
- **Google Colab / VS Code** for implementation

---

## üß† Reflections So Far

- Building these applications without abstraction helped me understand what goes *under the hood* in tools like LangChain.
- Chunking strategies, embedding choices, and vector DB querying dramatically affect retrieval quality.
- Having clear mental models of memory and agent behavior is essential for building real-world assistants.

---

## üöß Work in Progress

I am actively working through each notebook and pushing my modified versions into this repo. This includes:
- Markdown-based notes after every major block
- Errors I encountered and how I fixed them
- Additional experiments: different embeddings, chunk sizes, prompt styles

---

## üîó References & Credits

- Original Author: [**Hamza Farooq**](https://github.com/hamzafarooq)
- Repo: [https://github.com/hamzafarooq/building-llm-applications-from-scratch](https://github.com/hamzafarooq/building-llm-applications-from-scratch)
- Tools used: OpenAI, LangChain, LlamaIndex, ChromaDB, FAISS

---

## ‚ú® My Long-Term Plan

This is part of my broader journey into building intelligent assistants and tools with LLMs. I plan to eventually:
- Create a research-focused agent that helps me write papers
- Build knowledge-grounded chat systems on my own datasets
- Possibly write a blog or tutorial series based on what I learned

---

‚≠êÔ∏è Feel free to star or fork this repo if you're on a similar journey.
